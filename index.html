<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>

<meta charset="UTF-8">
<title>Short Course of Deep Learning 2016 Autumn(深度学习短期课程2016秋)</title>
    <meta name="viewport" content="width=device-width,inital-scale=1.0,minimum-scale=0.5,maximum-scale=2.0,user-scalable=no">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="css/normalize.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="css/cayman.css">


    <link rel="stylesheet" type="text/css" href="css/component.css" />

<!-- js for convnet -->  
<!-- bootstrap -->
  <link rel="stylesheet" type="text/css" href="convnet_demo/bootstrap.min.css">

      <script src="convnet_demo/convnet-min.js"></script>
      <script src="convnet_demo/convnet_demo.js"></script>

      <script>
      function page_loaded() {
        $('#convask').click(function(){
          $("#explain").slideToggle('fast');
        })
        start_convnet_demo();
      }
      </script>


  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-46895817-2', 'auto');
  ga('send', 'pageview');
  </script>


</head>
<section class="page-header">
      <h1 class="project-name">Short Course of Deep Learning 2016 Autumn</h1>
      <h2 class="project-tagline">深度学习短期课程2016秋</h2>
      <h3><script type="text/JavaScript" src="./js/timer.js"></script></h3>
      <!-- <a href="#" class="btn"></a> -->
    </section>



<body onload="page_loaded()">
<!-- <body background="cittext.gif" bgcolor="#FFFFFF" text="#000000" link="#33CC00" vlink="#FF6633" alink="#FFCC00"> -->

<div id="layout-content">
<div id="toptitle">
<!-- <h1>Short Course of Deep Learning 2016 Autumn(深度学习短期课程2016秋)</h1> -->
</div>

<!-- Welcome Words -->
<p align="left"> <b><font size="5">&nbsp; </font></b>
<font size="5">
<marquee behavior="alternate" align="middle" style="font-family: Helvetica; color: #0000FF" onmouseover = stop() onmouseout = start()>WELCOME TO DEEP LEARNING!</marquee></font>
</p>



<!-- Magic Words -->
<div class="content content--1">
        <svg width="100%" height="100%" viewBox="0 0 320 180" class="letters letters--effect-1">
          <!--W-->
          <g class="letter letter--1">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M25,39.7l22.4,51l7.9-32.2L76.2,84l1.3-61.2" />
              <path class="letter__layer color-1" d="M25,39.7l22.4,51l7.9-32.2L76.2,84l1.3-61.2" />
              <path class="letter__layer color-2" d="M25,39.7l22.4,51l7.9-32.2L76.2,84l1.3-61.2" />
            </g>
          </g>
          <!--I-->
          <g class="letter letter--2">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M100,20.3l8.4,58.4" />
              <path class="letter__layer color-2" d="M100,20.3l8.4,58.4" />
              <path class="letter__layer color-3" d="M100,20.3l8.4,58.4" />
            </g>
          </g>
          <!--L-->
          <g class="letter letter--3">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M126.4,70.8l27.6,0.5" />
              <path class="letter__layer color-3" d="M126.4,70.8l27.6,0.5" />
              <path class="letter__layer color-4" d="M126.4,70.8l27.6,0.5" />
            </g>
            <g class="letter__part">
              <path class="letter__layer color-6" d="M128.9,15.6l-2.3,60.2" />
              <path class="letter__layer color-3" d="M128.9,15.6l-2.3,60.2" />
              <path class="letter__layer color-4" d="M128.9,15.6l-2.3,60.2" />
            </g>
          </g>
          <!--D-->
          <g class="letter letter--4">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M167.4,27.6l3.7,49.1" />
              <path class="letter__layer color-4" d="M167.4,27.6l3.7,49.1" />
              <path class="letter__layer color-5" d="M167.4,27.6l3.7,49.1" />
            </g>
            <g class="letter__part">
              <path class="letter__layer color-6" d="M157.8,30.9c0,0,31.2-10.9,40.3,6.8c8.9,17-23.5,38.4-35,42.6" />
              <path class="letter__layer color-4" d="M157.8,30.9c0,0,31.2-10.9,40.3,6.8c8.9,17-23.5,38.4-35,42.6" />
              <path class="letter__layer color-5" d="M157.8,30.9c0,0,31.2-10.9,40.3,6.8c8.9,17-23.5,38.4-35,42.6" />
            </g>
          </g>
          <!--E-->
          <g class="letter letter--5">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M215,52l25.6,2.8" />
              <path class="letter__layer color-5" d="M215,52l25.6,2.8" />
              <path class="letter__layer color-1" d="M215,52l25.6,2.8" />
            </g>
            <g class="letter__part">
              <path class="letter__layer color-6" d="M211.8,76.9l30.6,3.4" />
              <path class="letter__layer color-5" d="M211.8,76.9l30.6,3.4" />
              <path class="letter__layer color-1" d="M211.8,76.9l30.6,3.4" />
            </g>
            <g class="letter__part">
              <path class="letter__layer color-6" d="M218.6,27.4l30.9,2.9" />
              <path class="letter__layer color-5" d="M218.6,27.4l30.9,2.9" />
              <path class="letter__layer color-1" d="M218.6,27.4l30.9,2.9" />
            </g>
            <g class="letter__part">
              <path class="letter__layer color-6" d="M218.4,22.4l-6.9,59.6" />
              <path class="letter__layer color-5" d="M218.4,22.4l-6.9,59.6" />
              <path class="letter__layer color-1" d="M218.4,22.4l-6.9,59.6" />
            </g>
          </g>
          <!--R-->
          <g class="letter letter--6">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M264.2,29.8l24.1,8c12,4.2,12,11,9.4,18.5c-2.6,7.5-6.7,12.9-18.7,8.8l-14.2-4.8" />
              <path class="letter__layer color-4" d="M264.2,29.8l24.1,8c12,4.2,12,11,9.4,18.5c-2.6,7.5-6.7,12.9-18.7,8.8l-14.2-4.8" />
              <path class="letter__layer color-2" d="M264.2,29.8l24.1,8c12,4.2,12,11,9.4,18.5c-2.6,7.5-6.7,12.9-18.7,8.8l-14.2-4.8" />
            </g>
            <g class="letter__part">
              <path class="letter__layer color-6" d="M284.9,96.2l-20.4-35.1" />
              <path class="letter__layer color-4" d="M284.9,96.2l-20.4-35.1" />
              <path class="letter__layer color-2" d="M284.9,96.2l-20.4-35.1" />
            </g>
            <g class="letter__part">
              <path class="letter__layer color-6" d="M275.2,29.4l-20.5,60.6" />
              <path class="letter__layer color-4" d="M275.2,29.4l-20.5,60.6" />
              <path class="letter__layer color-2" d="M275.2,29.4l-20.5,60.6" />
            </g>
          </g>
          <!--M-->
          <g class="letter letter--7">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M72.9,156.9l-7.1-56.5L91.7,127l18.8-29.8l7.1,56.5" />
              <path class="letter__layer color-3" d="M72.9,156.9l-7.1-56.5L91.7,127l18.8-29.8l7.1,56.5" />
              <path class="letter__layer color-1" d="M72.9,156.9l-7.1-56.5L91.7,127l18.8-29.8l7.1,56.5" />
            </g>
          </g>
          <!--I-->
          <g class="letter letter--8">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M144.9,99.5l-6,61.3" />
              <path class="letter__layer color-4" d="M144.9,99.5l-6,61.3" />
              <path class="letter__layer color-2" d="M144.9,99.5l-6,61.3" />
            </g>
          </g>
          <!--N-->
          <g class="letter letter--9">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M170.4,161.9l-3.2-61.8l43.4,58.1l-7.2-62.6" />
              <path class="letter__layer color-1" d="M170.4,161.9l-3.2-61.8l43.4,58.1l-7.2-62.6" />
              <path class="letter__layer color-3" d="M170.4,161.9l-3.2-61.8l43.4,58.1l-7.2-62.6" />
            </g>
          </g>
          <!--D-->
          <g class="letter letter--10">
            <g class="letter__part">
              <path class="letter__layer color-6" d="M233.8,107.9l3.9,51.7" />
              <path class="letter__layer color-5" d="M233.8,107.9l3.9,51.7" />
              <path class="letter__layer color-4" d="M233.8,107.9l3.9,51.7" />
            </g>
            <g class="letter__part">
              <path class="letter__layer color-6" d="M222.4,109.4c0,0,33.9-11.8,43.8,7.4c10.9,20.9-23.6,43.4-34.8,47.5" />
              <path class="letter__layer color-5" d="M222.4,109.4c0,0,33.9-11.8,43.8,7.4c10.9,20.9-23.6,43.4-34.8,47.5" />
              <path class="letter__layer color-4" d="M222.4,109.4c0,0,33.9-11.8,43.8,7.4c10.9,20.9-23.6,43.4-34.8,47.5" />
            </g>
          </g>
        </svg>
      </div>


<!--  Convolutional Neural Network -->

<div id="teaser">
<div id="convnetvis"></div>
<span class="glyphicon glyphicon-question-sign" id="convask"></span>
<div id="demomsg">
The Convolutional Neural Network in this example is classifying images live in your browser using Javascript
</div>
</div>

<div class="container"
  <div id="explain">
    The Convolutional Neural Network in this example is classifying images live in your browser using Javascript, at about 10 milliseconds per image. It takes an input image and transforms it through a series of functions into class probabilities at the end. The transformed representations in this visualization can be losely thought of as the activations of the neurons along the way. The parameters of this function are learned with backpropagation on a dataset of (image, label) pairs. This particular network is classifying <a href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> images into one of 10 classes and was trained with <a href="http://cs.stanford.edu/people/karpathy/convnetjs/">ConvNetJS</a>. Its exact architecture is [conv-relu-conv-relu-pool]x3-fc-softmax, for a total of 17 layers and 7000 parameters. It uses 3x3 convolutions and 2x2 pooling regions. By the end of the class, you will know exactly what all these numbers mean.
  </div>
</div>




<!-- Short Course  -->
<ul>
<li><p>深度学习短期课程<a href="Syllabus.pdf">课程大纲</a>及<a href="poster.pdf">简介海报</a></p>
</li>
<li><p>教师信息：<a href="http://bicmr.pku.edu.cn/~dongbin">董彬</a>， dongbin@math.pku.edu.cn ; <a href="http://bicmr.pku.edu.cn/~wenzw">文再文</a>，wenzw@math.pku.edu.cn</p>
</li>
<li><p>负责人信息: 李冠淳,pku_liguanchun@163.com; 李正一,lizhengyi@pku.edu.cn; 谢玙,xieyu0824@126.com; 姚嘉豪,zxc604036406@foxmail.com</p>
</li>
<li><p>上课时间:周四晚上7:00-9:00</p>
</li>
<li><p>地点:三教501</p>
</li>
</ul>
<ul>
<li><p>深度学习参考材料</p>
<ul>
<li><p><a href="http://cs231n.stanford.edu">Stanford CS231n: Convolutional Neural Networks for Visual Recognition</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/intelligentunit">CS231n笔记授权翻译连载及深度增强学习原创文章</a></p>
</li>
<li><p><a href="https://cn.mathworks.com/matlabcentral/fileexchange/38310-deep-learning-toolbox">A Matlab toolbox for Deep Learning</a></p>
</li>
<li><p><a href="http://www.deeplearningbook.org">Deep Learning textbook by Ian Goodfellow and Yoshua Bengio and Aaron Courville</a></p>
</li>
<li><p><a href="http://ufldl.stanford.edu/tutorial">Programming exercises for the Stanford Unsupervised Feature Learning and Deep Learning Tutorial</a></p>
</li>
<li><p><a href="http://deeplearning.cs.cmu.edu">Lab Course in Deep Learning</a></p>
</li>
<li><p><a href="http://www.iro.umontreal.ca/%7Ebengioy/papers/ftml_book.pdf">Learning Deep Architectures for AI</a></p>
</li>
<li><p><a href="http://neuralnetworksanddeeplearning.com">Neural Networks and Deep Learning</a></p>
</li>
<li><p><a href="http://120.52.73.79/arxiv.org/pdf/1601.04920.pdf">Understanding Deep Convolutional Networks</a></p>
</li>
<li><p><a href="http://120.52.73.75/arxiv.org/pdf/1509.07385.pdf">Provable approximation properties for deep neural networks</a></p>
</li>
<li><p><a href="http://arxiv.org/pdf/1312.5548v1.pdf">My First Deep Learning System of 1991 + Deep Learning Timeline 1962-2013</a></p>
</li>
<li><p><a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">Deep learning Yann LeCun Yoshua Bengio &amp; Geoffrey Hinton</a></p>
</li>
<li><p><a href="http://joanbruna.github.io/stat212b/">Stat212b: Topics Course on Deep Learning</a></p>
</li>
<li><p><a href="http://cs224d.stanford.edu/project.html">CS224d: Deep Learning for Natural Language Processing</a></p>
</li>
<li><p><a href="http://suanfazu.com/t/mlss2016-by-john-schulman-uc-berkeley/13451">深度强化学习(MLSS2016) by John Schulman<a href="UC">Berkeley</a></a></p>
</li>
<li><p><a href="http://rll.berkeley.edu/deeprlcourse/">CS 294: Deep Reinforcement Learning, Fall 2015</a></p>
</li>
<li><p><a href="./literature/awesome-free-deep-learning-papers.html">More Reference</a></p>
</li>
<li><p><a href="https://bcourses.berkeley.edu/courses/1453965/wiki">CS294-129 Designing, Visualizing and Understanding Deep Neural Networks</a></p>
</li>
<li><p><a href="http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/">26 THINGS I LEARNED IN THE DEEP LEARNING SUMMER SCHOOL</a></p>
</li>
<li><p><a href="http://videolectures.net/deeplearning2016_montreal/">Deep Learning Summer School 2016</a></p>
</li>
<li><p><a href="http://videolectures.net/deeplearning2015_montreal/">Deep Learning Summer School 2015</a></p>
</li></ul>
</li>
<li><p>课程信息 （大致安排）</p>
<ul>
<li><p><b>Acknowledgement: I would like to thank  Prof. Fei-Fei Li (Stanford). Most of the slides are motivated or even taken directly from their courses.</b></p>
</li>
<li><p>第1周，9月22日，<a href="http://cs231n.stanford.edu/slides/winter1516_lecture2.pdf">k-nearest neighbor, Linear classification</a>
<br />
主讲人：李冠淳</p>
</li>
<li><p>第2周，9月29日，
<a href="http://cs231n.github.io/python-numpy-tutorial">Python(Introduction, examples from part 1)</a>
以及<a href="http://cs231n.stanford.edu/slides/winter1516_lecture3.pdf">Optimization, stochastic gradient descent</a>
<br />
主讲人：李冠淳
<br />
阅读材料: </p>
<ul>
<li><p><a href="http://int8.io/comparison-of-optimization-techniques-stochastic-gradient-descent-momentum-adagrad-and-adadelta/#Adam">Optimization techniques comparison in Julia: SGD, Momentum, Adagrad, Adadelta, Adam</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/22252270?from=timeline&amp;isappinstalled=0">SGD，Adagrad，Adadelta，Adam，Adamax，Nadam</a></p>
</li>
<li><p><a href="./literature/Nocedal_Wright_Numerical_optimization_v2.pdf">Numerical Optimization chapter 8 automatic differentiation</a></p>
</li></ul>
</li>
<li><p>第3周，10月6日，国庆节放假 </p>
</li>
<li><p>第4周，10月13日，<a href="./Talks/BP&amp;NN.pptx.zip">Backpropagation, Introduction to neural networks</a>
<br />
主讲人：姚嘉豪
<br />
阅读材料: </p>
<ul>
<li><p><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Efficient BackProp</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1502.05767v2.pdf">Automatic differentiation in machine learning: a survey</a></p>
</li>
<li><p><a href="http://colah.github.io/posts/2015-08-Backprop/">Calculus on Computational Graphs: Backpropagation</a></p>
</li>
<li><p><a href="http://neuralnetworksanddeeplearning.com/chap2.html">How the backpropagation algorithm works</a></p>
</li>
<li><p><a href="https://www.linkedin.com/pub/dario-amodei/4/493/393">Dario Amodei</a></p>
</li>
<li><p><a href="http://michaelnielsen.org/">Michael Nielsen</a></p>
</li>
<li><p><a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html">Yoshua Bengio</a></p>
</li></ul>
</li>
<li><p>第5周，10月20日，Training Neural Networks 
<br />
主讲人：李正一
<br /></p>
<ul>
<li><p><a href="https://arxiv.org/pdf/1502.03167v3.pdf">Batch Normalization</a></p>
</li>
<li><p><a href="https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html">Understanding the backward pass through Batch Normalization Layer</a></p>
</li>
<li><p><a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=10&amp;ved=0ahUKEwjur-aw0O3PAhWCVZQKHRzzDUkQFghgMAk&amp;url=https%3A%2F%2Fbcourses.berkeley.edu%2Ffiles%2F66022277%2Fdownload%3Fdownload_frd%3D1%26verifier%3DoaU8pqXDDwZ1zidoDBTgLzR8CPSkWe6MCBKUYan7&amp;usg=AFQjCNGHyy4qhRcwLLU2RunAgM3iqFMcjQ&amp;bvm=bv.136593572,d.dGo&amp;cad=rja">Batch Normalization in Neural Network</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1510.01378v1.pdf">Batch Normalized Recurrent Neural Networks</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1603.09025v4.pdf">Recurrent Batch Normalization</a></p>
</li>
<li><p><a href="http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/">Softmax Regression</a></p>
</li>
<li><p><a href="http://ufldl.stanford.edu/wiki/index.php/Softmax_Regression">Softmax Regression</a></p>
</li></ul>
</li>
<li><p>第6周，10月27日，Training Neural Networks
<br />
主讲人：李正一
<br /></p>
<ul>
<li><p><a href="http://sebastianruder.com/optimizing-gradient-descent/index.html">An overview of gradient descent optimization algorithms</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1506.08700v4">Dropout as data augmentation</a></p>
</li></ul>
</li>
<li><p>第7周，11月3日，<a href="./Talks/CNN1.pdf">Convolutional Neural Networks</a>
<br />
主讲人：谢玙
<br /></p>
<ul>
<li><p><a href="https://arxiv.org/abs/1409.4842v1">GoogLeNet</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1512.03385v1">ResNet</a></p>
</li></ul>
</li>
<li><p>第8周，11月10日，<a href="./Talks/LocalizationDetection.pdf">Convolutional Neural Networks</a>
<br />
主讲人：谢玙
<br /></p>
<ul>
<li><p><a href="https://arxiv.org/abs/1311.2524">RCNN</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1504.08083">Fast R-CNN</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1506.01497v3">Faster R-CNN</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1506.02640v4">YOLO</a></p>
</li>
<li><p><a href="http://blog.csdn.net/column/details/ym-alanyannick.html">深度学习RCNN系列详解（含RCNN,Fast RCNN, Faster RCNN, YOLO的论文讲解）</a></p>
</li></ul>
</li>
<li><p>第9周，11月17日， <a href="http://cs231n.stanford.edu/slides/winter1516_lecture9.pdf">Convolutional Neural Networks</a>
<br />
主讲人：谢玙
<br /></p>
<ul>
<li><p><a href="https://github.com/KaimingHe/deep-residual-networks">Deep Residual Learning for Image Recognition</a></p>
</li>
<li><p><a href="https://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf">Rich feature hierarchies for accurate object detection and semantic segmentation</a></p>
</li>
<li><p><a href="http://cs.stanford.edu/people/karpathy/cnnembed/">t-SNE visualization of CNN codes</a></p>
</li>
<li><p><a href="http://www.sciencedirect.com/science/article/pii/S0022391352800150">Experiments in occlusion</a></p>
</li>
<li><p><a href="http://yosinski.com/deepvis">Understanding Neural Networks Through Deep Visualization</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1311.2901">Visualizing and Understanding Convolutional Networks</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1312.6034">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1412.6806">Striving for Simplicity: The All Convolutional Net</a></p>
</li>
<li><p><a href="https://github.com/google/deepdream">deepdream</a></p>
</li>
<li><p><a href="https://github.com/jcjohnson/neural-style">Torch implementation of neural style algorithm</a></p>
</li>
<li><p><a href="www.cs.nyu.edu/~zaremba/docs/understanding.pdf">Intriguing properties of neural networks</a></p>
</li>
<li><p><a href="https://www.researchgate.net/publication/221430186_Exploring_the_representation_capabilities_of_the_HOG_descriptor?enrichId=rgreq-9694231208fb264722ba909fc1d906d7-XXX&amp;enrichSource=Y292ZXJQYWdlOzIyMTQzMDE4NjtBUzo5NzYzOTA0MzQzNjU0N0AxNDAwMjkwMzcwNTIz&amp;el=1_x_3">Exploring the representation capabilities of the HOG descriptor</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1412.6572">Explaining and Harnessing Adversarial Examples</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1312.6034.pdf">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1412.1897v1.pdf">Deep Neural Networks are Easily Fooled:High Confidence Predictions for Unrecognizable Images</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1508.06576v1.pdf">A Neural Algorithm of Artistic Style</a>  <br /></p>
</li></ul>
</li>
<li><p>第10周，11月24日，<a href="./Talks/lecture1123.pptx">Recurrent Neural Networks (RNN), Long Short Term Memory (LSTM)</a>
<br />
主讲人：李冠淳
<br /></p>

<ul>
<li><p><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/#more-107">RNN的介绍</a></p>
</li>
<li><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM的介绍</a></p>
</li>
<li><p><a href="http://blog.csdn.net/shincling/article/details/49362161#0-tsina-1-98891-397232819ff9a47a7b7e80a40613cfe1">RNN 及 LSTM公式梳理</a></p>
</li>

<li><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></p>
</li>

</li></ul>
</li>
<li><p>第11周，11月31日，<a href="./Talks/CNNinPractice.pdf">Training ConvNets in practice</a>    
<br />
主讲人：谢玙
<br /></p>
<ul>
<li><p><a href="https://github.com/FishXY/CNN-in-Practice">谢玙的卷积神经网络</a></p>
</li>
<li><p><a href="Intel®">Xeon Phi™  http:<i></i>www.nersc.gov<i>users</i>computational-systems<i>cori</i>cori-phase-ii/</a></p>
</li>
<li><p><a href="http://www.research.ibm.com/articles/brain-chip.shtml">TrueNorth chip</a>
<br /></p>
</li></ul>
</li>
<li><p>第12周，12月8日，<a href="./Talks/install.html">Overview</a> of <a href="http://caffe.berkeleyvision.org">Caffe</a>、<a href="http://torch.ch">Torch</a>、<a href="http://deeplearning.net/software/theano/">Theano</a>、<a href="https://www.tensorflow.org">TensorFlow</a>
<br />
主讲人：李正一
<br /></p>
<ul>
<li><p><a href="www.anaconda.org/zhengyi/class1">正一的class1</a>、<a href="www.anaconda.org/zhengyi/class2">正一的class1</a></p>
</li>
<li><p>￼Caffe: Python  Interface</p>
<ul>
<li><p><a href="https://github.com/BVLC/caffe/python/caffe/_caffe.cpp">Exports Blob, Layer, Net, and Solver classes</a></p>
</li>
<li><p><a href="https://github.com/BVLC/caffe/python/caffe/pycaffe.py">Adds extra methods to Net class</a></p>
</li></ul>
</li>
<li><p>￼Torch: Pretrained Models</p>
<ul>
<li><p><a href="https://github.com/soumith/inception.torch">GoogLeNet v1</a></p>
</li>
<li><p><a href="https://github.com/Moodstocks/inception-v3.torch">GoogLeNet v3</a> </p>
</li>
<li><p><a href="https://github.com/facebook/fb.resnet.torch">ResNet</a></p>
</li>
<li><p><a href="https://github.com/szagoruyko/loadcaffe">loadcaffe: Load pretrained Caffe models: AlexNet, VGG, some others</a></p>
</li>
<li><p><a href="https://github.com/soumith/cudnn.torch">torch.cudnn</a>: Bindings for NVIDIA cuDNN kernel</p>
</li>
<li><p><a href="https://github.com/deepmind/torch-hdf5">torch-hdf5:</a>Read and write HDF5 files from Torch</p>
</li>
<li><p><a href="https://luarocks.org/modules/luarocks/lua-cjson">lua-cjson</a> Read and write JSON files from Lua</p>
</li>
<li><p><a href="https://github.com/hughperkins/cltorch">cltorch</a>、<a href="https://github.com/hughperkins/clnn">clnn</a> OpenCL backend for Torch, and port of nn </p>
</li>
<li><p><a href="https://github.com/twitter/torch-autograd">torch-autograd</a> Automatic differentiation; sort of like more powerful nngraph, similar to Theano or TensorFlow</p>
</li>
<li><p><a href="https://github.com/facebook/fbcunn">fbcunn</a> Facebook: FFT conv, multi-GPU (DataParallel, ModelParallel) </p>
</li></ul>
</li>
<li><p>Theano: Pretrained Models</p>
<ul>
<li><p><a href="https://github.com/Lasagne/Recipes/tree/master/modelzoo">Lasagne Model Zoo</a> has pretrained common architectures</p>
</li>
<li><p><a href="https://github.com/uoguelph-mlrg/theano_alexnet">AlexNet with weights</a></p>
</li>
<li><p><a href="http://sklearn-theano.github.io">sklearn-theano</a> Run OverFeat and GoogLeNet forward, but no finetuning? </p>
</li>
<li><p><a href="https://github.com/kitofans/caffe-theano-conversion">caffe-theano-conversion</a>load models and weights from caffe! Not sure if full-featured</p>
</li></ul>
</li>
<li><p>￼TensorFlow: Pretrained Models </p>
<ul>
<li><p><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md">a pretrained version of Inception</a>
<br /></p>
</li></ul>
</li></ul>
</li>
<li><p>第13周，12月15日，<a href="./Talks/SgAt20161215.pdf">Segmentation</a>
<br />
主讲人：姚嘉豪
<br /></p>
<ul>
<li><p><a href="http://yann.lecun.com/exdb/publis/pdf/farabet-pami-13.pdf">Learning Hierarchical Features for Scene Labeling</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1306.2795v1.pdf">RECURRENT CONVOLUTIONAL NEURAL NETWORKS FOR SCENE PARSING</a></p>
</li>
<li><p><a href="http://machinelearning.wustl.edu/mlpapers/paper_files/icml2014c1_pinheiro14.pdf">Recurrent Convolutional Neural Networks for Scene Labeling</a></p>
</li>
<li><p><a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">Fully Convolutional Networks for Semantic Segmentation</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1602.05110v5.pdf">Generating images with recurrent adversarial networks</a></p>
</li>
<li><p><a href="http://www.robots.ox.ac.uk/~szheng/papers/CRFasRNN.pdf">Conditional Random Fields as Recurrent Neural Networks</a></p>
</li>
<li><p><a href="https://people.eecs.berkeley.edu/~arbelaez/publications/ahggbm_cvpr2012.pdf">Semantic Segmentation using Regions and Parts</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1512.04412v1.pdf">Instance-aware Semantic Segmentation via Multi-task Network Cascades</a></p>
</li>
<li><p><a href="https://people.eecs.berkeley.edu/~rbg/papers/BharathECCV2014.pdf">Simultaneous Detection and Segmentation</a></p>
</li>
<li><p><a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/shape/sds/">Simultaneous Detection and Segmentation</a></p>
</li>
<li><p><a href="https://www.zybuluo.com/zhenni94/note/228566">Simultaneous Detection and Segmentation Notes</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1511.08250v3.pdf">Recurrent Instance Segmentation</a></p>
</li>
<li><p><a href="https://www.zhihu.com/question/51704852">Instance Segmentation 比 Semantic Segmentation 难很多吗？</a></p>
</li>
<li><p><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Chen_Multi-Instance_Object_Segmentation_2015_CVPR_paper.pdf">Multi-instance Object Segmentation with Occlusion Handling</a></p>
</li>
<li><p><a href="https://www.inf.ethz.ch/personal/ladickyl/video_bmvc11.pdf">Human Instance Segmentation from Video using Detector-based Conditional Random Fields</a></p>
</li>
<li><p><a href="https://github.com/kjw0612/awesome-deep-vision">Awesome Deep Vision</a></p>
</li>
<li><p><a href="https://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention.pdf">Recurrent Models of Visual Attention</a>
<br /></p>
</li></ul>
</li>
<li><p>第14周，12月22日， <a href="./Talks/AttGan20161222.pdf.zip">Soft attention models, Spatial transformer networks , Generative Adversial Network</a>
<br />
主讲人：姚嘉豪
<br /></p>
<ul>
<li><p><a href="http://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf">A Connection Between Score Matching and Denoising Autoencoders</a></p>
</li>
<li><p><a href="http://www.deeplearningbook.org/contents/autoencoders.html">Chapter 14 Autoencoders</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1312.6114v10.pdf">Auto-Encoding Variational Bayes</a></p>
</li>
<li><p><a href="https://www.microsoft.com/cognitive-services/en-us/computer-vision-api">Computer Vision API</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1608.07068v2.pdf">Title Generation for User Generated Videos</a></p>
</li>
<li><p><a href="http://ms-multimedia-challenge.com/challenge">Video to Language Challenge</a></p>
</li>
<li><p><a href="https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/">Video Frame Analysis Sample</a></p>
</li>
<li><p><a href="soumith.ch/eyescream/">The Eyescream Project</a></p>
</li>
<li><p><a href="https://github.com/lisa-lab/pylearn2">Pylearn2: A machine learning research library</a></p>
</li>
<li><p><a href="https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning/answer/Yann-LeCun">Yann LeCun's answer to What are some recent and potentially upcoming breakthroughs in deep learning?</a></p>
</li>
<li><p><a href="https://github.com/goodfeli/adversarial">Code and hyperparameters for the paper &ldquo;Generative Adversarial Networks&rdquo;</a></p>
</li>
<li><p><a href="blog.csdn.net/shenxiaolu1984/article/details/52215983">生成对抗网络Generative Adversarial Nets</a> </p>
</li>
<li><p><a href="https://arxiv.org/pdf/1503.08909v2.pdf">Beyond Short Snippets: Deep Networks for Video Classification</a></p>
</li>
<li><p><a href="www.cs.cmu.edu/~rahuls/pub/cvpr2014-deepvideo-rahuls.pdf">Large-scale Video Classification with Convolutional Neural Networks</a></p>
</li>
<li><p><a href="cs.stanford.edu/people/karpathy/deepvideo/">Large-scale Video Classification with Convolutional Neural Networks</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1612.05424.pdf">Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1506.05751">Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/1511.06434">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></p>
</li>
<li><p><a href="blog.csdn.net/shenxiaolu1984/article/details/51493673">Show, attend and tell算法详解</a></p>
</li>
</ul>

</li>
</ul>

</li>
</ul>

<ul>
<li>
<ul>
<li><p>第15周，12月29日，Merry Christmas and Happy New Year</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<a href="IMGLINKTARGET"><img src="happy-new-year.jpeg" alt="alt text" width="100%" height="100%" /></a>&nbsp;</td>
<td align="left">
</td></tr></table>
<ul>
<li><p>课程项目文献</p>
<ul>
<li><p><a href="http://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf">Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion</a></p>
</li>
</ul>

</li>
</ul>



<!-- jQuery and Boostrap -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>

</div>

</body>
</html>


</body>
</html>